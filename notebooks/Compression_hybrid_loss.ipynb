{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/M1croZavr/compression_horizon/blob/task%2Fhybrid_loss/notebooks/Compression_hybrid_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guZNmrc5UCCQ"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L5BBf1oUaYQ"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    subprocess.check_output([\"nvidia-smi\"], shell=True)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"nvidia-smi is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAC3zQmr3yxX"
   },
   "outputs": [],
   "source": [
    "!git clone --branch task/hybrid_loss https://github.com/M1croZavr/compression_horizon.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5c3kR1s9ui-"
   },
   "source": [
    "# Experiments launching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eD3R8Pv_9xMr"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "# %tensorboard --logdir=/content/compression_horizon/artifacts/experiments/common_loss\n",
    "# %tensorboard --logdir=/content/compression_horizon/artifacts/experiments/hybrid_loss\n",
    "%tensorboard --logdir=/content/drive/MyDrive/compression_horizon/22-11-2025/hybrid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa180eBPZRRC"
   },
   "source": [
    "## Common loss launches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1Rr8R35P-RO"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 4 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQTcbxnEb0Us"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 32 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f97sUuBlcgBN"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QyXdLFZdz61"
   },
   "outputs": [],
   "source": [
    "!cp -R /content/compression_horizon/artifacts/experiments/common_loss ./drive/MyDrive/compression_horizon/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrt0UmdkZyJY"
   },
   "source": [
    "## Hybrid loss launches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaCe5kv59uLs"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run --no-dev python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 4 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type l2 --hybrid_alpha 0.2 --num_alignment_layers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evcS73Ad9uJZ"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 32 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type l2 --hybrid_alpha 0.2 --num_alignment_layers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akLNidEiBOBt"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type l2 --hybrid_alpha 0.2 --num_alignment_layers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kP2OWJfCF1zC"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type cosine --hybrid_alpha 0.2 --num_alignment_layers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQ4W1inPI-Jo"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type l1 --hybrid_alpha 0.2 --num_alignment_layers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jy6y7RKeNsgx"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type cosine --hybrid_alpha 0.5 --num_alignment_layers 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqohHPltRHAg"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type cosine --hybrid_alpha 1 --num_alignment_layers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9fZeKNV8Ctk"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run --no-dev python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type cosine --hybrid_alpha 1 --num_alignment_layers 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrG3OrfbBFxo"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run --no-dev python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type cosine --hybrid_alpha 1 --num_alignment_layers 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0oul01QBH22"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run --no-dev python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type l2 --hybrid_alpha 1 --num_alignment_layers 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gi1dj-lQBKFT"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run --no-dev python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type l1 --hybrid_alpha 1 --num_alignment_layers 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0APj-guuKghe"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run --no-dev python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type l2 --hybrid_alpha 0.1 --num_alignment_layers 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XyTB1oVKjwa"
   },
   "outputs": [],
   "source": [
    "!cd ./compression_horizon/; uv run --no-dev python scripts/hybrid_loss.py --model_checkpoint HuggingFaceTB/SmolLM2-1.7B --learning_rate 0.01 --max_sequence_length 128 --number_of_mem_tokens 1 --max_optimization_steps_per_sample 1000 --warmup_steps 100 --loss_type l1 --hybrid_alpha 0.1 --num_alignment_layers 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3RIjsPwBtnk"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/compression_horizon/artifacts/experiments/hybrid_loss /content/drive/MyDrive/compression_horizon/22-11-2025/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj8kml4plT8f"
   },
   "source": [
    "# CE comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgKC8Quvmagj"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98PsCFQ3ndyi"
   },
   "outputs": [],
   "source": [
    "# checkpoint = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "checkpoint = \"HuggingFaceTB/SmolLM2-1.7B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, dtype=torch.float32).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.add_special_tokens({\"pad_token\": tokenizer.eos_token});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAGOj474lelH"
   },
   "outputs": [],
   "source": [
    "# Load the exact sample (index 0)\n",
    "raw_dataset = load_dataset(\"mrsndmn/pg19\", split=\"test\")\n",
    "train_dataset = raw_dataset.select(range(1))\n",
    "example = tokenizer(train_dataset[0][\"text\"], truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "input_ids = example[\"input_ids\"].to(device)\n",
    "attention_mask = example[\"attention_mask\"].to(device)\n",
    "with torch.no_grad():\n",
    "    sequence_embeddings = model.get_input_embeddings()(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "en--nALoixtZ"
   },
   "outputs": [],
   "source": [
    "def load_compression_embeddings(path: str, device: str | torch.device = \"cpu\") -> torch.Tensor:\n",
    "    result = load_from_disk(path)\n",
    "    compression_embeddings = torch.FloatTensor(result[0][\"embedding\"]).unsqueeze(dim=0).to(device)\n",
    "    return compression_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnDwZdSUnKkj"
   },
   "outputs": [],
   "source": [
    "def calculate_logits(\n",
    "    compression_embeddings: torch.Tensor,\n",
    "    sequence_embeddings: torch.Tensor,\n",
    "    attention_mask: torch.Tensor,\n",
    "    model: PreTrainedModel,\n",
    ") -> torch.Tensor:\n",
    "    united_embeddings = torch.cat(\n",
    "        (compression_embeddings, sequence_embeddings),\n",
    "        dim=1,\n",
    "    )\n",
    "    # TODO: Adjust code implementation to support > 1 compression tokens\n",
    "    united_attention_mask = torch.cat(\n",
    "        (torch.tensor([[1]]).to(device), attention_mask),\n",
    "        dim=1,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            inputs_embeds=united_embeddings,\n",
    "            attention_mask=united_attention_mask,\n",
    "        )\n",
    "    return outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mG930EVwlejH"
   },
   "outputs": [],
   "source": [
    "compression_embeddings = load_compression_embeddings(\n",
    "    \"/content/drive/MyDrive/compression_horizon/common_loss/\"\n",
    "    \"HuggingFaceTB/SmolLM2-1.7B|128|1|bc818cdb-8346-4cf1-beb0-7459ce626638/compressed_prefixes/\",\n",
    "    device,\n",
    ")\n",
    "logits = calculate_logits(compression_embeddings, sequence_embeddings, attention_mask, model)\n",
    "# TODO: Adjust implementation to support > 1 compression tokens\n",
    "print(\n",
    "    \"Common loss cross entropy:\", torch.nn.functional.cross_entropy(logits[:, :-1, :].flatten(0, 1), input_ids.flatten()).item()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h35yZmaUlKDQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "hybrid_loss_results_root = pathlib.Path(\"/content/drive/MyDrive/compression_horizon/22-11-2025/hybrid_loss/\")\n",
    "for result_dir in os.listdir(hybrid_loss_results_root):\n",
    "    compression_embeddings = load_compression_embeddings(\n",
    "        hybrid_loss_results_root / result_dir / \"compressed_prefixes\",\n",
    "        device,\n",
    "    )\n",
    "    logits = calculate_logits(compression_embeddings, sequence_embeddings, attention_mask, model)\n",
    "    print(\n",
    "        result_dir,\n",
    "        \"\\n\\tHybrid loss cross entropy:\",\n",
    "        torch.nn.functional.cross_entropy(logits[:, :-1, :].flatten(0, 1), input_ids.flatten()).item(),\n",
    "        end=\"\\n\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEGPvHqkojJA"
   },
   "outputs": [],
   "source": [
    "hybrid_loss_results_root = pathlib.Path(\"/content/drive/MyDrive/compression_horizon/17-11-2025/hybrid_loss/HuggingFaceTB/\")\n",
    "for result_dir in os.listdir(hybrid_loss_results_root):\n",
    "    if \"|128|\" in result_dir:\n",
    "        try:\n",
    "            compression_embeddings = load_compression_embeddings(\n",
    "                hybrid_loss_results_root / result_dir / \"compressed_prefixes\",\n",
    "                device,\n",
    "            )\n",
    "            logits = calculate_logits(compression_embeddings, sequence_embeddings, attention_mask, model)\n",
    "            print(\n",
    "                result_dir,\n",
    "                \"\\n\\tHybrid loss cross entropy:\",\n",
    "                torch.nn.functional.cross_entropy(logits[:, :-1, :].flatten(0, 1), input_ids.flatten()).item(),\n",
    "                end=\"\\n\\n\",\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvWYTWu2JhwM"
   },
   "source": [
    "# Generation outside the compressed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rN_DNVGaygj7"
   },
   "outputs": [],
   "source": [
    "from compression_horizon.src.compression_horizon.inference.generation import generate_from_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5CCGKOR6Ccm"
   },
   "outputs": [],
   "source": [
    "# Ground truth for sequence length 128\n",
    "print(tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9zAsR4Oyign"
   },
   "source": [
    "## Embeddings trained on common loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_E4popByu4H"
   },
   "outputs": [],
   "source": [
    "compression_embeddings = load_compression_embeddings(\n",
    "    \"/content/drive/MyDrive/compression_horizon/common_loss/HuggingFaceTB/\"\n",
    "    \"SmolLM2-1.7B|128|1|bc818cdb-8346-4cf1-beb0-7459ce626638/compressed_prefixes/\",\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qeda7MClyux3"
   },
   "outputs": [],
   "source": [
    "print(generate_from_compression(model, tokenizer, compression_embeddings, 256, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XvlJ1nRyr8G"
   },
   "source": [
    "## Embeddings trained on hybrid loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6eJT_EsKRpl"
   },
   "outputs": [],
   "source": [
    "compression_embeddings = load_compression_embeddings(\n",
    "    \"/content/drive/MyDrive/compression_horizon/17-11-2025/hybrid_loss/HuggingFaceTB/\"\n",
    "    \"SmolLM2-1.7B|128|1|0.01|cosine|1.0|5|978c86f1-57ac-4eba-a446-6a6dc874d451/compressed_prefixes/\",\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ui3CPqQQyOgJ"
   },
   "outputs": [],
   "source": [
    "print(generate_from_compression(model, tokenizer, compression_embeddings, 256, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F7ocPGt0Yhq"
   },
   "source": [
    "# Average distance between compression embeddings and (actual sequence/random sequence embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-1MmGQr9YRh"
   },
   "outputs": [],
   "source": [
    "def calculate_distances(compression_embeddings: torch.Tensor, sequence_embeddings: torch.Tensor) -> tuple[float]:\n",
    "    # Cosine\n",
    "    cosine = F.cosine_similarity(compression_embeddings, sequence_embeddings, dim=-1)\n",
    "    cosine = (1.0 - cosine).mean().item()\n",
    "    # l2\n",
    "    l2 = torch.sqrt(torch.sum((sequence_embeddings - compression_embeddings) ** 2, dim=-1)).mean().item()\n",
    "    # l1\n",
    "    l1 = torch.sum(torch.abs(sequence_embeddings - compression_embeddings), dim=-1).mean().item()\n",
    "    return cosine, l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bP9ylFKDtsSs"
   },
   "outputs": [],
   "source": [
    "actual_sequence = input_ids\n",
    "actual_embeddings = sequence_embeddings\n",
    "\n",
    "random_sequence = torch.randint(0, tokenizer.vocab_size, input_ids.size(), device=device)\n",
    "with torch.no_grad():\n",
    "    random_embeddings = model.get_input_embeddings()(random_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nXgOmAn9J6W"
   },
   "outputs": [],
   "source": [
    "# Common\n",
    "compression_embeddings = load_compression_embeddings(\n",
    "    \"/content/drive/MyDrive/compression_horizon/common_loss/HuggingFaceTB/\"\n",
    "    \"SmolLM2-1.7B|128|1|bc818cdb-8346-4cf1-beb0-7459ce626638/compressed_prefixes/\",\n",
    "    device,\n",
    ")\n",
    "cosine, l2, l1 = calculate_distances(compression_embeddings, actual_embeddings)\n",
    "print(f\"Cosine: {cosine} | l2: {l2} | l1: {l1}\")\n",
    "cosine, l2, l1 = calculate_distances(compression_embeddings, random_embeddings)\n",
    "print(f\"Cosine: {cosine} | l2: {l2} | l1: {l1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LieWM4iy-fp4"
   },
   "outputs": [],
   "source": [
    "# Hybrid\n",
    "hybrid_loss_results_root = pathlib.Path(\"/content/drive/MyDrive/compression_horizon/17-11-2025/hybrid_loss/HuggingFaceTB/\")\n",
    "for result_dir in os.listdir(hybrid_loss_results_root):\n",
    "    if \"|128|\" in result_dir:\n",
    "        try:\n",
    "            compression_embeddings = load_compression_embeddings(\n",
    "                hybrid_loss_results_root / result_dir / \"compressed_prefixes\",\n",
    "                device,\n",
    "            )\n",
    "            cosine, l2, l1 = calculate_distances(compression_embeddings, actual_embeddings)\n",
    "            cosine_r, l2_r, l1_r = calculate_distances(compression_embeddings, random_embeddings)\n",
    "            print(\n",
    "                result_dir,\n",
    "                \"\\n\\tHybrid loss result:\",\n",
    "                f\"\\n\\tCosine: {cosine} | l2: {l2} | l1: {l1}\\n\\tCosine: {cosine_r} | l2: {l2_r} | l1: {l1_r}\",\n",
    "                end=\"\\n\\n\",\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0U2LBwl8slW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPKHmDn2ZuQh4pR9szRkrDB",
   "collapsed_sections": [
    "fa180eBPZRRC",
    "hrt0UmdkZyJY"
   ],
   "gpuType": "T4",
   "include_colab_link": true,
   "mount_file_id": "1hAXcU_UMO5aH1JktJz-WP-CKlMENJk-H",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}